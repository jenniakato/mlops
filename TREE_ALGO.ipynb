{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7620951b",
   "metadata": {},
   "source": [
    "## MLflow Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a99b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlflow\n",
    "#!pip install --upgrade jinja2\n",
    "#!pip install --upgrade Flask\n",
    "#!pip install setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e208dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import de librairie\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score , classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ee6a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connecxion au serveur MLFlow\n",
    "client= MlflowClient(tracking_uri=\"http://127.0.0.1:8080\")\n",
    "## Configuration \n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa9c2ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Experiment: artifact_location='mlflow-artifacts:/606383372813198707', creation_time=1760806668542, experiment_id='606383372813198707', last_update_time=1760806668542, lifecycle_stage='active', name='TREE_Models', tags={'mlflow.experimentKind': 'custom_model_development'}>, <Experiment: artifact_location='mlflow-artifacts:/389458555972686615', creation_time=1760804935652, experiment_id='389458555972686615', last_update_time=1760804935652, lifecycle_stage='active', name='RLG_Models', tags={'mlflow.experimentKind': 'custom_model_development'}>, <Experiment: artifact_location='mlflow-artifacts:/668826699846372727', creation_time=1760799130123, experiment_id='668826699846372727', last_update_time=1760799130123, lifecycle_stage='active', name='RDF_Models', tags={'mlflow.experimentKind': 'custom_model_development'}>, <Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1760798921200, experiment_id='0', last_update_time=1760798921200, lifecycle_stage='active', name='Default', tags={}>]\n"
     ]
    }
   ],
   "source": [
    "# R√©cup√©ration de toutes les exp√©riences MLflow\n",
    "all_experiments = client.search_experiments()\n",
    "# Affichage des exp√©riences \n",
    "print(all_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb7e4ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='mlflow-artifacts:/606383372813198707', creation_time=1760806668542, experiment_id='606383372813198707', last_update_time=1760806668542, lifecycle_stage='active', name='TREE_Models', tags={'mlflow.experimentKind': 'custom_model_development'}>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recherche des exp√©riences Mlflow Sp√©cifique.\n",
    "client.search_experiments(filter_string=\"name = 'TREE_Models'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945c4ba8",
   "metadata": {},
   "source": [
    "## Chargement du fichier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "add13bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   person_age  person_income person_home_ownership  person_emp_length loan_intent loan_grade  loan_amnt  loan_int_rate  loan_status  loan_percent_income cb_person_default_on_file  cb_person_cred_hist_length\n",
      "0          22          59000                  RENT              123.0    PERSONAL          D      35000          16.02            1                 0.59                         Y                           3\n",
      "1          21           9600                   OWN                5.0   EDUCATION          B       1000          11.14            0                 0.10                         N                           2\n",
      "2          25           9600              MORTGAGE                1.0     MEDICAL          C       5500          12.87            1                 0.57                         N                           3\n"
     ]
    }
   ],
   "source": [
    "# D√©finition du chemin vers le fichier de  donn√©es \n",
    "data_dir = r\"C:\\Users\\j_aka\\Desktop\\mlops\\credit_risk_dataset.csv\"\n",
    "# Chargement de la donn√©es \n",
    "df = pd.read_csv(data_dir, delimiter=\",\") \n",
    "#Affichage des 3 premi√®res lignes \n",
    "print(df.head(3).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50e744e",
   "metadata": {},
   "source": [
    "## D√©cision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5b588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/19 16:20:23 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\j_aka\\anaconda3\\envs\\mlops_projet\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "c:\\Users\\j_aka\\anaconda3\\envs\\mlops_projet\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mod√®le entra√Æn√© et logu√© dans MLflow avec succ√®s.\n",
      "\n",
      "Rapport de classification :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      5072\n",
      "           1       0.91      0.72      0.80      1445\n",
      "\n",
      "    accuracy                           0.92      6517\n",
      "   macro avg       0.92      0.85      0.88      6517\n",
      "weighted avg       0.92      0.92      0.92      6517\n",
      "\n",
      "\n",
      "Matrice de confusion :\n",
      " [[4972  100]\n",
      " [ 410 1035]]\n",
      "üìä M√©triques : {'accuracy': 0.921743133343563, 'precision': 0.9118942731277533, 'recall': 0.7162629757785467, 'f1': 0.8023255813953488}\n",
      "üèÉ View run TREE_Run at: http://127.0.0.1:8080/#/experiments/606383372813198707/runs/401b7b68908840948320077326fc2bef\n",
      "üß™ View experiment at: http://127.0.0.1:8080/#/experiments/606383372813198707\n"
     ]
    }
   ],
   "source": [
    "# D√©finition des Features et de la cible \n",
    "target_col = 'loan_status'\n",
    "X = df.drop(columns=['loan_status'])    \n",
    "y = df['loan_status']\n",
    "\n",
    "# Split des donn√©es \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Colonne num√©rique et colonne cat√©gorielle \n",
    "num_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_features = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "#Encoder et G√©rer les donn√©es Nan \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers= [\n",
    "        (\"num_features\", SimpleImputer(strategy=\"mean\"), num_features),\n",
    "        (\"cat_features\", OneHotEncoder(handle_unknown=\"ignore\"),cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Hyperparam√®tre du mod√®le\n",
    "params = {\n",
    "    \"criterion\": \"gini\",\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 10,\n",
    "    \"min_samples_leaf\": 4,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "# Nom du mod√®le : \n",
    "mlflow.set_experiment(\"TREE_Models\")\n",
    "# Nom du run pour cette it√©ration d'entra√Ænement\n",
    "run_name = \"TREE_Run\"\n",
    "# les artefacts du mod√®le\n",
    "artifact_path = \"TREE_artefacts\"\n",
    "# Fermer tout run pr√©c√©dent\n",
    "#mlflow.end_run()\n",
    "\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    # Tag de version du mod√®le\n",
    "    mlflow.set_tag(\"version\", \"v1.0\")\n",
    "\n",
    "# Encodage et entrainement du mod√®le \n",
    "    pipeline_fr = Pipeline(steps=[\n",
    "    (\"processor\", preprocessor),\n",
    "    (\"model\", DecisionTreeClassifier(**params))\n",
    "   ])\n",
    "    \n",
    "# Entrainement du mod√®le\n",
    "    pipeline_fr.fit(X_train,y_train)\n",
    "\n",
    "# Pr√©diction du mod√®le\n",
    "    y_proba = pipeline_fr.predict_proba(X_val)[:, 1]\n",
    "    y_pred = (y_proba >= 0.3).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# Calcul des m√©triques\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    metrics = {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model= pipeline_fr, \n",
    "        input_example=X_val, \n",
    "        artifact_path= artifact_path\n",
    "    ) \n",
    "\n",
    "    print(\"‚úÖ Mod√®le entra√Æn√© et logu√© dans MLflow avec succ√®s.\")\n",
    "    print(\"\\nRapport de classification :\\n\", classification_report(y_val, y_pred))\n",
    "    print(\"\\nMatrice de confusion :\\n\", confusion_matrix(y_val, y_pred))\n",
    "    print(\"üìä M√©triques :\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97549ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "print(mlflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36bdf355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nom : TREE_Models | ID : 606383372813198707\n",
      "Nom : RLG_Models | ID : 389458555972686615\n",
      "Nom : RDF_Models | ID : 668826699846372727\n",
      "Nom : Default | ID : 0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "experiments = mlflow.search_experiments()\n",
    "for exp in experiments:\n",
    "    print(f\"Nom : {exp.name} | ID : {exp.experiment_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26c54bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID : 401b7b68908840948320077326fc2bef\n",
      "Artefacts : mlflow-artifacts:/606383372813198707/401b7b68908840948320077326fc2bef/artifacts\n",
      "Run ID : f55fcd44eb874d41a9bc1a8bccdddcdc\n",
      "Artefacts : mlflow-artifacts:/606383372813198707/f55fcd44eb874d41a9bc1a8bccdddcdc/artifacts\n",
      "Run ID : 990f13fdba71400f8bc519d45326c5c4\n",
      "Artefacts : mlflow-artifacts:/606383372813198707/990f13fdba71400f8bc519d45326c5c4/artifacts\n",
      "Run ID : b7ad840cf8e648bab020b034954d92f4\n",
      "Artefacts : mlflow-artifacts:/606383372813198707/b7ad840cf8e648bab020b034954d92f4/artifacts\n",
      "Run ID : 3b3a105dba904beabd5e18a267368ccc\n",
      "Artefacts : mlflow-artifacts:/606383372813198707/3b3a105dba904beabd5e18a267368ccc/artifacts\n",
      "Run ID : 4ed00a71bbb94973b62828662e438dc4\n",
      "Artefacts : mlflow-artifacts:/606383372813198707/4ed00a71bbb94973b62828662e438dc4/artifacts\n",
      "Run ID : b83c4cd06ad04d17a8f485050210adde\n",
      "Artefacts : mlflow-artifacts:/606383372813198707/b83c4cd06ad04d17a8f485050210adde/artifacts\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[\"606383372813198707\"],\n",
    "    filter_string=\"tags.version = 'v1.0'\"\n",
    ")\n",
    "\n",
    "for run in runs:\n",
    "    print(\"Run ID :\", run.info.run_id)\n",
    "    print(\"Artefacts :\", run.info.artifact_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6edea9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ TREE_artefacts/MLmodel\n",
      "üì¶ TREE_artefacts/conda.yaml\n",
      "üì¶ TREE_artefacts/input_example.json\n",
      "üì¶ TREE_artefacts/model.pkl\n",
      "üì¶ TREE_artefacts/python_env.yaml\n",
      "üì¶ TREE_artefacts/requirements.txt\n",
      "üì¶ TREE_artefacts/serving_input_example.json\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "artifacts = client.list_artifacts(\"b7ad840cf8e648bab020b034954d92f4\", path=\"TREE_artefacts\")\n",
    "\n",
    "for artifact in artifacts:\n",
    "    print(\"üì¶\", artifact.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9069900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6151228957754777\n",
      "0.5838532740986542\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Pr√©dictions\n",
    "y_train_pred = pipeline_fr.predict(X_train)\n",
    "y_val_pred = pipeline_fr.predict(X_val)\n",
    "\n",
    "# M√©triques\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(train_r2)\n",
    "print(val_r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_projet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
